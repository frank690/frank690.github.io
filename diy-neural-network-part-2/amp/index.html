<!DOCTYPE html>
<html âš¡>
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,minimum-scale=1,initial-scale=1">

    <title>Building a Framework</title>

    <meta name="description" content="Part 2 is all about restructuring the code of our previously made neural network so we can use it in a way more elegant way, much like frameworks like Tensorflow or PyTorch." />
    <link rel="canonical" href="../index.html" />
    <meta name="referrer" content="no-referrer-when-downgrade" />
    
    <meta property="og:site_name" content="sffresch" />
    <meta property="og:type" content="article" />
    <meta property="og:title" content="Building a Framework" />
    <meta property="og:description" content="Part 2 is all about restructuring the code of our previously made neural network so we can use it in a way more elegant way, much like frameworks like Tensorflow or PyTorch." />
    <meta property="og:url" content="http://frank690.github.io/diy-neural-network-part-2/" />
    <meta property="og:image" content="https://images.unsplash.com/photo-1444530495635-029990f82ce8?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;MnwxMTc3M3wwfDF8c2VhcmNofDE0fHxzZWVkbGluZ3xlbnwwfHx8fDE2NTIzNTM0NTY&amp;ixlib&#x3D;rb-1.2.1&amp;q&#x3D;80&amp;w&#x3D;2000" />
    <meta property="article:published_time" content="2022-05-12T11:02:59.000Z" />
    <meta property="article:modified_time" content="2022-12-23T09:03:24.000Z" />
    <meta property="article:tag" content="ANN" />
    <meta property="article:tag" content="DIY" />
    <meta property="article:tag" content="python" />
    <meta property="article:tag" content="neural-network-series" />
    
    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="Building a Framework" />
    <meta name="twitter:description" content="Part 2 is all about restructuring the code of our previously made neural network so we can use it in a way more elegant way, much like frameworks like Tensorflow or PyTorch." />
    <meta name="twitter:url" content="http://frank690.github.io/diy-neural-network-part-2/" />
    <meta name="twitter:image" content="https://images.unsplash.com/photo-1444530495635-029990f82ce8?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;MnwxMTc3M3wwfDF8c2VhcmNofDE0fHxzZWVkbGluZ3xlbnwwfHx8fDE2NTIzNTM0NTY&amp;ixlib&#x3D;rb-1.2.1&amp;q&#x3D;80&amp;w&#x3D;2000" />
    <meta name="twitter:label1" content="Written by" />
    <meta name="twitter:data1" content="Frank Eschner" />
    <meta name="twitter:label2" content="Filed under" />
    <meta name="twitter:data2" content="ANN, DIY, python, neural-network-series" />
    <meta property="og:image:width" content="2000" />
    <meta property="og:image:height" content="1325" />
    
    <script type="application/ld+json">
{
    "@context": "https://schema.org",
    "@type": "Article",
    "publisher": {
        "@type": "Organization",
        "name": "sffresch",
        "url": "http://frank690.github.io/",
        "logo": {
            "@type": "ImageObject",
            "url": "http://frank690.github.io/favicon.ico",
            "width": 48,
            "height": 48
        }
    },
    "author": {
        "@type": "Person",
        "name": "Frank Eschner",
        "image": {
            "@type": "ImageObject",
            "url": "http://frank690.github.io/content/images/2021/08/68586209_10205828296182785_2060227135364136960_n.jpg"
        },
        "url": "http://frank690.github.io/author/frank690/",
        "sameAs": [
            "https://sffresch.de"
        ]
    },
    "headline": "Building a Framework",
    "url": "http://frank690.github.io/diy-neural-network-part-2/",
    "datePublished": "2022-05-12T11:02:59.000Z",
    "dateModified": "2022-12-23T09:03:24.000Z",
    "image": {
        "@type": "ImageObject",
        "url": "https://images.unsplash.com/photo-1444530495635-029990f82ce8?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDE0fHxzZWVkbGluZ3xlbnwwfHx8fDE2NTIzNTM0NTY&ixlib=rb-1.2.1&q=80&w=2000",
        "width": 2000,
        "height": 1325
    },
    "keywords": "ANN, DIY, python, neural-network-series",
    "description": "Part 2 is all about restructuring the code of our previously made neural network so we can use it in a way more elegant way, much like frameworks like Tensorflow or PyTorch. ",
    "mainEntityOfPage": {
        "@type": "WebPage",
        "@id": "http://frank690.github.io/"
    }
}
    </script>

    <meta name="generator" content="Ghost 5.26" />
    <link rel="alternate" type="application/rss+xml" title="sffresch" href="../../rss/index.html" />

    <style amp-custom>
    *,
    *::before,
    *::after {
        box-sizing: border-box;
    }

    html {
        overflow-x: hidden;
        overflow-y: scroll;
        font-size: 62.5%;
        -webkit-tap-highlight-color: rgba(0, 0, 0, 0);
    }

    body {
        min-height: 100vh;
        margin: 0;
        padding: 0;
        color: #3a4145;
        font-family: -apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen,Ubuntu,Cantarell,Open Sans,Helvetica Neue,sans-serif;
        font-size: 1.7rem;
        line-height: 1.55em;
        font-weight: 400;
        font-style: normal;
        background: #fff;
        scroll-behavior: smooth;
        overflow-x: hidden;
        -webkit-font-smoothing: antialiased;
        -moz-osx-font-smoothing: grayscale;
    }

    p,
    ul,
    ol,
    li,
    dl,
    dd,
    hr,
    pre,
    form,
    table,
    video,
    figure,
    figcaption,
    blockquote {
        margin: 0;
        padding: 0;
    }

    ul[class],
    ol[class] {
        padding: 0;
        list-style: none;
    }

    img {
        display: block;
        max-width: 100%;
    }

    input,
    button,
    select,
    textarea {
        font: inherit;
        -webkit-appearance: none;
    }

    fieldset {
        margin: 0;
        padding: 0;
        border: 0;
    }

    label {
        display: block;
        font-size: 0.9em;
        font-weight: 700;
    }

    hr {
        position: relative;
        display: block;
        width: 100%;
        height: 1px;
        border: 0;
        border-top: 1px solid currentcolor;
        opacity: 0.1;
    }

    ::selection {
        text-shadow: none;
        background: #cbeafb;
    }

    mark {
        background-color: #fdffb6;
    }

    small {
        font-size: 80%;
    }

    sub,
    sup {
        position: relative;
        font-size: 75%;
        line-height: 0;
        vertical-align: baseline;
    }
    sup {
        top: -0.5em;
    }
    sub {
        bottom: -0.25em;
    }

    ul li + li {
        margin-top: 0.6em;
    }

    a {
        color: var(--ghost-accent-color, #1292EE);
        text-decoration-skip-ink: auto;
    }

    h1,
    h2,
    h3,
    h4,
    h5,
    h6 {
        margin: 0;
        font-weight: 700;
        color: #121212;
        line-height: 1.4em;
    }

    h1 {
        font-size: 3.4rem;
        line-height: 1.1em;
    }

    h2 {
        font-size: 2.4rem;
        line-height: 1.2em;
    }

    h3 {
        font-size: 1.8rem;
    }

    h4 {
        font-size: 1.7rem;
    }

    h5 {
        font-size: 1.6rem;
    }

    h6 {
        font-size: 1.6rem;
    }

    amp-img {
        height: 100%;
        width: 100%;
        max-width: 100%;
        max-height: 100%;
    }

    amp-img img {
        object-fit: cover;
    }
    
    amp-youtube {
        height: calc(100vw / 1.78);
        width: 100vw;
        position: relative;
    }

    amp-youtube img {
        position: absolute;
    }

    .page-header {
        padding: 50px 5vmin 30px;
        text-align: center;
        font-size: 2rem;
        text-transform: uppercase;
        letter-spacing: 0.5px;
    }

    .page-header a {
        color: #121212;
        font-weight: 700;
        text-decoration: none;
        font-size: 1.6rem;
        letter-spacing: -0.1px;
    }

    .post {
        max-width: 680px;
        margin: 0 auto;
    }

    .post-header {
        margin: 0 5vmin 5vmin;
        text-align: center;
    }

    .post-meta {
        margin: 1rem 0 0 0;
        text-transform: uppercase;
        color: #738a94;
        font-weight: 500;
        font-size: 1.3rem;
    }

    .post-image {
        margin: 0 0 5vmin;
    }

    .post-image img {
        display: block;
        width: 100%;
        height: auto;
    }

    .post-content {
        padding: 0 5vmin;
    }

    .post-content > * + * {
        margin-top: 1.5em;
    }

    .post-content [id]:not(:first-child) {
        margin: 2em 0 0;
    }

    .post-content > [id] + * {
        margin-top: 1rem;
    }

    .post-content [id] + .kg-card,
    .post-content blockquote + .kg-card {
        margin-top: 40px;
    }

    .post-content > ul,
    .post-content > ol,
    .post-content > dl {
        padding-left: 1.9em;
    }

    .post-content hr {
        margin-top: 40px;
    }

    .post .post-content hr + * {
        margin-top: 40px;
    }

    .post-content amp-img {
        background-color: #f8f8f8;
    }

    .post-content blockquote {
        position: relative;
        font-style: italic;
    }

    .post-content blockquote::before {
        content: "";
        position: absolute;
        left: -1.5em;
        top: 0;
        bottom: 0;
        width: 0.3rem;
        background: var(--ghost-accent-color, #1292EE);
    }

    .post-content blockquote.kg-blockquote-alt {
        font-size: 1.2em;
        font-style: italic;
        line-height: 1.6em;
        text-align: center;
        color: #738a94;
        padding: 0.75em 3em 1.25em;
    }

    .post-content blockquote.kg-blockquote-alt::before {
        display: none;
    }

    .post-content :not(.kg-card):not([id]) + .kg-card {
        margin-top: 40px;
    }

    .post-content .kg-card + :not(.kg-card) {
        margin-top: 40px;
    }

    .kg-card figcaption {
        padding: 1.5rem 1.5rem 0;
        text-align: center;
        font-weight: 500;
        font-size: 1.3rem;
        line-height: 1.4em;
        opacity: 0.6;
    }

    .kg-card figcaption strong {
        color: rgba(0,0,0,0.8);
    }

    .post-content :not(pre) code {
        vertical-align: middle;
        padding: 0.15em 0.4em 0.15em;
        border: #e1eaef 1px solid;
        font-weight: 400;
        font-size: 0.9em;
        line-height: 1em;
        color: #15171a;
        background: #f0f6f9;
        border-radius: 0.25em;
    }

    .post-content > pre {
        overflow: scroll;
        padding: 16px 20px;
        color: #fff;
        background: #1F2428;
        border-radius: 5px;
        box-shadow: 0 2px 6px -2px rgba(0,0,0,.1), 0 0 1px rgba(0,0,0,.4);
    }

    .kg-embed-card {
        display: flex;
        flex-direction: column;
        align-items: center;
        width: 100%;
    }

    .kg-image-card img {
        margin: auto;
    }

    .kg-gallery-card + .kg-gallery-card {
        margin-top: 0.75em;
    }

    .kg-gallery-container {
        position: relative;
    }

    .kg-gallery-row {
        display: flex;
        flex-direction: row;
        justify-content: center;
    }

    .kg-gallery-image {
        width: 100%;
        height: 100%;
    }

    .kg-gallery-row:not(:first-of-type) {
        margin: 0.75em 0 0 0;
    }

    .kg-gallery-image:not(:first-of-type) {
        margin: 0 0 0 0.75em;
    }

    .kg-bookmark-card,
    .kg-bookmark-publisher {
        position: relative;
    }

    .kg-bookmark-container,
    .kg-bookmark-container:hover {
        display: flex;
        flex-wrap: wrap;
        flex-direction: row-reverse;
        color: currentColor;
        background: rgba(255,255,255,0.6);
        font-family: -apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen,Ubuntu,Cantarell,Open Sans,Helvetica Neue,sans-serif;
        text-decoration: none;
        border-radius: 3px;
        box-shadow: 0 2px 6px -2px rgba(0, 0, 0, 0.1), 0 0 1px rgba(0, 0, 0, 0.4);
        overflow: hidden;
    }

    .kg-bookmark-content {
        flex-basis: 0;
        flex-grow: 999;
        padding: 20px;
        order: 1;
    }

    .kg-bookmark-title {
        font-weight: 600;
        font-size: 1.5rem;
        line-height: 1.3em;
    }

    .kg-bookmark-description {
        display: -webkit-box;
        max-height: 45px;
        margin: 0.5em 0 0 0;
        font-size: 1.4rem;
        line-height: 1.55em;
        overflow: hidden;
        opacity: 0.8;
        -webkit-line-clamp: 2;
        -webkit-box-orient: vertical;
    }

    .kg-bookmark-metadata {
        margin-top: 20px;
    }

    .kg-bookmark-metadata {
        display: flex;
        align-items: center;
        font-weight: 500;
        font-size: 1.3rem;
        line-height: 1.3em;
        white-space: nowrap;
        overflow: hidden;
        text-overflow: ellipsis;
    }

    .kg-bookmark-description {
        display: -webkit-box;
        -webkit-box-orient: vertical;
        -webkit-line-clamp: 2;
        overflow: hidden;
    }

    .kg-bookmark-metadata amp-img {
        width: 18px;
        height: 18px;
        max-width: 18px;
        max-height: 18px;
        margin-right: 10px;
    }

    .kg-bookmark-thumbnail {
        display: flex;
        flex-basis: 20rem;
        flex-grow: 1;
        justify-content: flex-end;
    }

    .kg-bookmark-thumbnail amp-img {
        max-height: 200px;
    }

    .kg-bookmark-author {
        white-space: nowrap;
        text-overflow: ellipsis;
        overflow: hidden;
    }

    .kg-bookmark-publisher::before {
        content: "â€¢";
        margin: 0 .5em;
    }

    .kg-toggle-card-icon {
        display: none;
    }

    .kg-toggle-content {
        margin-top: 0.8rem;
    }

    .kg-product-card-container {
        background: transparent;
        padding: 20px;
        width: 100%;
        border-radius: 5px;
        box-shadow: inset 0 0 0 1px rgb(124 139 154 / 25%);
    }

    .kg-product-card-description p {
        margin-top: 1.5em;
    }

    .kg-product-card-description ul {
        margin-left: 24px;
    }

    .kg-product-card-title {
        font-size: 1.9rem;
        font-weight: 700;
    }

    .kg-product-card-rating-star {
        height: 28px;
        width: 20px;
        margin-right: 2px;
    }

    .kg-product-card-rating-star svg {
    width: 16px;
    height: 16px;
    fill: currentColor;
    opacity: 0.15;
    }

    .kg-product-card-rating-active.kg-product-card-rating-star svg {
    opacity: 1;
    }

    .kg-nft-card-container {
        position: relative;
        display: flex;
        flex: auto;
        flex-direction: column;
        text-decoration: none;
        font-family: -apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen,Ubuntu,Cantarell,Open Sans,Helvetica Neue,sans-serif;
        font-size: 1.4rem;
        font-weight: 400;
        box-shadow: 0 2px 6px -2px rgb(0 0 0 / 10%), 0 0 1px rgb(0 0 0 / 40%);
        width: 100%;
        max-width: 512px;
        color: #15212A;
        background: #fff;
        border-radius: 5px;
        transition: none;
        margin: 0 auto;
    }

    .kg-nft-metadata {
        padding: 2.0rem;
    }

    .kg-nft-image-container {
        position: relative;
    }

    .kg-nft-image {
        display: flex;
        border-radius: 5px 5px 0 0;
    }

    .kg-nft-header {
        display: flex;
        justify-content: space-between;
        align-items: flex-start;
        gap: 20px;
    }

    .kg-nft-header h4.kg-nft-title {
        font-size: 1.9rem;
        font-weight: 700;
        margin: 0;
        color: #15212A;
    }

    .kg-nft-header amp-img {
        max-width: 114px;
        max-height: 26px;
    }

    .kg-nft-opensea-logo {
        margin-top: 2px;
        width: 100px;
    }

    .kg-nft-creator {
        font-family: inherit;
        color: #95A1AD;
    }

    .kg-nft-creator span {
        font-weight: 500;
        color: #15212A;
    }

    .kg-nft-card p.kg-nft-description {
        font-size: 1.4rem;
        line-height: 1.4em;
        margin: 2.0rem 0 0;
        color: #222;
    }

    .kg-button-card {
        display: flex;
        position: static;
        align-items: center;
        width: 100%;
        justify-content: center;
    }

    .kg-btn {
        display: flex;
        position: static;
        align-items: center;
        padding: 0 2.0rem;
        height: 4.0rem;
        line-height: 4.0rem;
        font-size: 1.65rem;
        font-weight: 600;
        text-decoration: none;
        border-radius: 5px;
        transition: opacity 0.2s ease-in-out;
    }

    .kg-btn:hover {
        opacity: 0.85;
    }

    .kg-btn-accent {
        background-color: var(--ghost-accent-color, #1292EE);
        color: #fff;
    }

    .kg-callout-card {
        display: flex;
        padding: 20px 28px;
        border-radius: 3px;
    }

    .kg-callout-card-grey {
        background: rgba(124, 139, 154, 0.13);
    }

    .kg-callout-card-white {
        background: transparent;
        box-shadow: inset 0 0 0 1px rgba(124, 139, 154, 0.25);
    }

    .kg-callout-card-blue {
        background: rgba(33, 172, 232, 0.12);
    }

    .kg-callout-card-green {
        background: rgba(52, 183, 67, 0.12);
    }

    .kg-callout-card-yellow {
        background: rgba(240, 165, 15, 0.13);
    }

    .kg-callout-card-red {
        background: rgba(209, 46, 46, 0.11);
    }

    .kg-callout-card-pink {
        background: rgba(225, 71, 174, 0.11);
    }

    .kg-callout-card-purple {
        background: rgba(135, 85, 236, 0.12);
    }

    .kg-callout-card-accent {
        background: var(--ghost-accent-color);
        color: #fff;
    }

    .kg-callout-card-accent a {
        color: #fff;
    }

    .kg-callout-emoji {
        padding-right: 16px;
        line-height: 1.3;
        font-size: 1.25em;
    }

    .kg-header-card {
        padding: 6em 3em;
        display: flex;
        flex-direction: column;
        align-items: center;
        justify-content: center;
        text-align: center;
    }

    .kg-header-card.kg-size-small {
        padding-top: 4em;
        padding-bottom: 4em;
    }

    .kg-header-card.kg-size-large {
        padding-top: 12em;
        padding-bottom: 12em;
    }

    .kg-header-card.kg-width-full {
        padding-left: 4em;
        padding-right: 4em;
    }

    .kg-header-card.kg-align-left {
        text-align: left;
        align-items: flex-start;
    }

    .kg-header-card.kg-style-dark {
        background: #15171a;
        color: #ffffff;
    }

    .kg-header-card.kg-style-light {
        color: #15171a;
        border: 1px solid rgba(124, 139, 154, 0.25);
        border-width: 1px 0;
    }

    .kg-header-card.kg-style-accent {
        background-color: var(--ghost-accent-color);
    }

    .kg-header-card.kg-style-image {
        background-color: #e7e7eb;
        background-size: cover;
        background-position: center center;
    }

    .kg-header-card h2 {
        font-size: 4em;
        font-weight: 700;
        line-height: 1.1em;
        margin: 0;
    }

    .kg-header-card h2 strong {
        font-weight: 800;
    }

    .kg-header-card.kg-size-small h2 {
        font-size: 3em;
    }

    .kg-header-card.kg-size-large h2 {
        font-size: 5em;
    }

    .kg-header-card h3 {
        font-size: 1.25em;
        font-weight: 500;
        line-height: 1.3em;
        margin: 0;
    }

    .kg-header-card h3 strong {
        font-weight: 600;
    }

    .kg-header-card.kg-size-small h3 {
        font-size: 1em;
    }

    .kg-header-card.kg-size-large h3 {
        font-size: 1.5em;
    }

    .kg-header-card:not(.kg-style-light) h2,
    .kg-header-card:not(.kg-style-light) h3 {
        color: #ffffff;
    }

    .kg-header-card a.kg-header-card-button {
        display: flex;
        position: static;
        align-items: center;
        padding: 0 1.2em;
        height: 2.4em;
        line-height: 1em;
        font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", "Roboto", "Oxygen", "Ubuntu", "Cantarell", "Fira Sans", "Droid Sans", "Helvetica Neue", sans-serif;
        font-size: 0.95em;
        font-weight: 600;
        text-decoration: none;
        border-radius: 5px;
        transition: opacity 0.2s ease-in-out;
        background-color: var(--ghost-accent-color);
        color: #ffffff;
        margin: 1.75em 0 0;
    }

    .kg-header-card a.kg-header-card-button:hover {
        opacity: 0.85;
    }

    .kg-header-card.kg-size-large a.kg-header-card-button {
        margin-top: 2em;
    }

    .kg-header-card.kg-size-small a.kg-header-card-button {
        margin-top: 1.5em;
    }

    .kg-header-card.kg-style-image a.kg-header-card-button,
    .kg-header-card.kg-style-dark a.kg-header-card-button {
        background: #ffffff;
        color: #15171a;
    }

    .kg-header-card.kg-style-accent a.kg-header-card-button {
        background: #ffffff;
        color: var(--ghost-accent-color);
    }

    .kg-audio-card {
        display: flex;
        width: 100%;
        box-shadow: inset 0 0 0 1px rgba(124, 139, 154, 0.25);
    }

    .kg-audio-thumbnail {
        display: flex;
        justify-content: center;
        align-items: center;
        width: 80px;
        min-width: 80px;
        height: 80px;
        background: transparent;
        object-fit: cover;
        aspect-ratio: 1/1;
        border-radius: 3px 0 0 3px;
    }

    .kg-audio-thumbnail.placeholder {
        background: var(--ghost-accent-color);
    }

    .kg-audio-thumbnail.placeholder svg {
        width: 24px;
        height: 24px;
        fill: white;
    }

    .kg-audio-player-container {
        position: relative;
        display: flex;
        flex-direction: column;
        justify-content: space-between;
        width: 100%;
        --seek-before-width: 0%;
        --volume-before-width: 100%;
        --buffered-width: 0%;
    }

    .kg-audio-title {
        width: 100%;
        padding: 8px 12px 0;
        border: none;
        font-family: inherit;
        font-size: 1.1em;
        font-weight: 700;
        background: transparent;
    }

    .kg-audio-player {
        display: none;
    }

    .kg-width-full.kg-card-hascaption {
        display: grid;
        grid-template-columns: inherit;
    }

    .post-content table {
        border-collapse: collapse;
        width: 100%;
    }

    .post-content th {
        padding: 0.5em 0.8em;
        text-align: left;
        font-size: .75em;
        text-transform: uppercase;
    }

    .post-content td {
        padding: 0.4em 0.7em;
    }

    .post-content tbody tr:nth-child(2n + 1) {
        background-color: rgba(0,0,0,0.1);
        padding: 1px;
    }

    .post-content tbody tr:nth-child(2n + 2) td:last-child {
        box-shadow:
            inset 1px 0 rgba(0,0,0,0.1),
            inset -1px 0 rgba(0,0,0,0.1);
    }

    .post-content tbody tr:nth-child(2n + 2) td {
        box-shadow: inset 1px 0 rgba(0,0,0,0.1);
    }

    .post-content tbody tr:last-child {
        border-bottom: 1px solid rgba(0,0,0,.1);
    }

    .page-footer {
        padding: 60px 5vmin;
        margin: 60px auto 0;
        text-align: center;
        background-color: #f8f8f8;
    }

    .page-footer h3 {
        margin: 0.5rem 0 0 0;
    }

    .page-footer p {
        max-width: 500px;
        margin: 1rem auto 1.5rem;
        font-size: 1.7rem;
        line-height: 1.5em;
        color: rgba(0,0,0,0.6)
    }

    .powered {
        display: inline-flex;
        align-items: center;
        margin: 30px 0 0;
        padding: 6px 9px 6px 6px;
        border: rgba(0,0,0,0.1) 1px solid;
        font-size: 12px;
        line-height: 12px;
        letter-spacing: -0.2px;
        font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", "Roboto", "Oxygen", "Ubuntu", "Cantarell", "Fira Sans", "Droid Sans", "Helvetica Neue", sans-serif;
        font-weight: 500;
        color: #222;
        text-decoration: none;
        background: #fff;
        border-radius: 6px;
    }

    .powered svg {
        height: 16px;
        width: 16px;
        margin: 0 6px 0 0;
    }

    @media (max-width: 600px) {
        body {
            font-size: 1.6rem;
        }
        h1 {
            font-size: 3rem;
        }

        h2 {
            font-size: 2.2rem;
        }
    }

    @media (max-width: 400px) {
        h1 {
            font-size: 2.6rem;
            line-height: 1.15em;
        }
        h2 {
            font-size: 2rem;
            line-height: 1.2em;
        }
        h3 {
            font-size: 1.7rem;
        }
    }

    :root {--ghost-accent-color: #650179;}
    </style>

    <style amp-boilerplate>body{-webkit-animation:-amp-start 8s steps(1,end) 0s 1 normal both;-moz-animation:-amp-start 8s steps(1,end) 0s 1 normal both;-ms-animation:-amp-start 8s steps(1,end) 0s 1 normal both;animation:-amp-start 8s steps(1,end) 0s 1 normal both}@-webkit-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@-moz-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@-ms-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@-o-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}</style><noscript><style amp-boilerplate>body{-webkit-animation:none;-moz-animation:none;-ms-animation:none;animation:none}</style></noscript>
    <script async src="https://cdn.ampproject.org/v0.js"></script>

    

</head>

<body class="amp-template">
    <header class="page-header">
        <a href="../../index.html">
                sffresch
        </a>
    </header>

    <main class="content" role="main">
        <article class="post">

            <header class="post-header">
                <h1 class="post-title">Building a Framework</h1>
                <section class="post-meta">
                    Frank Eschner -
                    <time class="post-date" datetime="2022-05-12">12 May 2022</time>
                </section>
            </header>
            <figure class="post-image">
                <amp-img src="https://images.unsplash.com/photo-1444530495635-029990f82ce8?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;MnwxMTc3M3wwfDF8c2VhcmNofDE0fHxzZWVkbGluZ3xlbnwwfHx8fDE2NTIzNTM0NTY&amp;ixlib&#x3D;rb-1.2.1&amp;q&#x3D;80&amp;w&#x3D;2000" width="600" height="340" layout="responsive" 
                alt="Building a Framework"
                ></amp-img>
            </figure>
            <section class="post-content">

                <p>This is part 2 of the DIY neural network series and it is all about restructuring the <a href="https://github.com/frank690/sffresch-code/blob/main/diy-neural-network-part-1/code.ipynb">code</a> of our <a href="http://frank690.github.io/diy-neural-network-part-2/diy-neural-network-part-1">previously made neural network</a> so we can use it in a way more elegant way, much like frameworks like <a href="https://www.tensorflow.org/">Tensorflow</a> or <a href="https://pytorch.org/">PyTorch</a>. For this purpose, we will construct a base class and consistently add more features and complexity to it within this and the following parts of the series.</p><p><strong>TL;DR</strong>: <a href="https://github.com/frank690/sffresch-code/blob/main/diy-neural-network-part-2/code.ipynb">Take me to the nice code</a>.</p><h3 id="the-base-class">The base class</h3><p>Artificial neural networks (ANNs) can consist of a variety of differently shaped layers and have various activation and loss functions. Being able to choose from these possibilities, when creating an ANN (programmatically) easily and elegantly, is key. First, we will come up with a class representation for a simple ANN that expects a list of integers as input, which represent the number of neurons in each layer.</p><pre><code class="language-python">class ANN:
    """
    Class representation of an artificial neural network (ANN).
    """
    def __init__(self, layers: List[int]):
        """
        Initialization function to set up the class.
        :param layers: Number of neurons for each layer that should be set up as List of ints.
        """
        self.W = dict()  # holding the weight matrices
        self.b = dict()  # holding the bias values
        self.z = dict()  # holding the intermediate values
        self.a = dict()  # holding the activation values
        
        self.dW = dict()  # holding the gradient of the weight matrices
        self.db = dict()  # holding the gradient of the bias values
        
        self.layers = layers  # User defined layers

        self._construct()
        
    def _construct(self):
        """
        Construct the internal shape of the ANN.
        """
        for idx, layer in enumerate(self.layers[:-1]):
            self.W[idx] = np.random.randn(layer, self.layers[idx+1])
            self.b[idx] = np.zeros(self.layers[idx+1])</code></pre><p>With the information about the neurons in each layer, the basic weight and bias structure (which will be optimized during the training process) is implemented. For now, the initial weight values are derived from a <a href="https://en.wikipedia.org/wiki/Normal_distribution">normal Gaussian distribution</a> and the bias values are set to plain zeros. Note that during the class initialization, there are four other dictionaries added to the class parameters. These hold information about the derivates of the weights ($dW$) and biases ($db$) but also about some intermediate ($z$) and activation values ($a$).</p><h3 id="the-cost-function">The cost function</h3><p>Depending on what kind of problem you want to solve, a variety of cost functions are applicable. Here we are going to stick with the cross-entropy-loss, that we already introduced in the <a href="http://frank690.github.io/diy-neural-network-part-2/diy-neural-network-part-1/">previous post of this series</a>. We accomplish this by adding the following method to our base class. Note that by providing a boolean true as the gradient parameter, we return the derivative of the loss. At a later point, we will provide a variety of loss functions and (ideally) grant the user the opportunity to implement custom functions, as well.</p><pre><code class="language-python">def loss(self, y: np.ndarray, gradient: bool = False) -&gt; np.ndarray:
    """
    Compute the cross entropy loss for the given hypothesis (h) in contrast to the true results (y).
    If the gradient flag is True, the derivative of said loss function will be returned.
    :param y: True output data.
    :param gradient: Bool flag to indicate if gradient should be returned.
    :return: Cost/Loss of the current hypothesis.
    """
    h = self.a[len(self.layers)-2]  # our prediction / hypothesis

    if gradient:
    	return -(y // h) + ((1 - y) // (1 - h))
    return -(1/y.size) * ((y.T @ np.log(h)) + ((1 - y.T) @ np.log(1 - h)))</code></pre><h3 id="the-activation-function">The activation function</h3><p>Just like the cost function, the activation function also highly depends on the problem that one wants to solve. One of the classic approaches is to use the <a href="https://en.wikipedia.org/wiki/Sigmoid_function">Sigmoid function</a>. We add this functionality with the following code snippet. Also here, we are granting the user the opportunity to get the gradient of the activation function by passing the boolean gradient flag, accordingly.</p><pre><code class="language-python">def activation(self, X: np.ndarray, gradient: bool = False) -&gt; np.ndarray:
    """
    For the activation function we use the sigmoid.
    It will return 0 for every x &lt;&lt; 0 and 1 for every x &gt;&gt; 0.
    Return the gradient of the sigmoid if a True gradient flag is given.
    :param X: data to transform via sigmoid function:
    :return: transformed data that lies between 0 and 1.
    """
    sigmoid = 1 / (1 + np.exp(-X))
    if gradient:
    	return sigmoid * (1 - sigmoid)
    return sigmoid</code></pre><h3 id="propagate-forward">Propagate forward</h3><p>Part of training an ANN and also a mandatory part to make predictions is the ability to propagate forward. Since the number of layers is decided upon the class initialization, we have to loop over all given weights and biases and compute the resulting intermediate ($z$) and activation values ($a$). The computed values will then be stored in the already existing dictionaries for said values.</p><pre><code class="language-python">def forward(self, X: np.ndarray):
    """
    Successively propagate the input data (X) through the ANN and store all
    intermediate and activation values in their corresponding dictionaries.
    :param X: Input data to make predictions on.
    """
    self.a[-1] = X
    for idx in range(len(self.layers)-1):
        self.z[idx] = self.a[idx-1] @ self.W[idx] + self.b[idx]
        self.a[idx] = self.activation(self.z[idx])</code></pre><h3 id="propagate-backward">Propagate backward</h3><p>Once we propagated forward through the whole ANN, our hypothesis (e.g. prediction) is represented by the output of the latest activation value. Next, we compute the loss and work our way backward through the network until we reached (computed) all derivations (gradients) of all our weights and biases. With these derivations ($dW$ and $db$) we head on to update our weights and biases.</p><pre><code class="language-python">def backward(self, y: np.ndarray):
    """
    Successively propagate the prediction as well as the true output backwards through the ANN.
    Store the resulting gradients for weights and biases in their corresponding dictionaries.
    :param y: True output data.
    """
    da = self.loss(y=y, gradient=True)  # get gradient of last activation value

    for idx in range(len(self.layers)-2, -1, -1):  # loop from the last layer to zero (effectively)
        dz = da * self.activation(X=self.z[idx], gradient=True)
        da = dz @ self.W[idx].T  

        self.db[idx] = np.mean(dz, axis=0)  # get gradient of bias. use mean to pay respect to sample size.
        self.dW[idx] = (self.a[idx-1].T @ dz) / y.size  # get gradient of weights. divide by number of samples.  </code></pre><h3 id="predict">Predict</h3><p>To predict the output, given some data, all we need to do is propagate said data forward through the network and look at the resulting hypothesis (e.g. activation value of the very last layer). Since we are only dealing with binary classification at this point, we apply an (arbitrary) threshold to the resulting predictions. This results in the predictions of our network being absolute (either class 0 or 1) for each provided sample.</p><pre><code class="language-python">def predict(self, X: np.ndarray, threshold: float = 0.5) -&gt; np.ndarray:
    """
    Predict the output of the given data (X).
    :param X: Data to make prediction on.
    :param threshold: Threshold that decides if predicted value belongs to class 0 or 1.
    :return: Predicted value.
    """
    self.forward(X)
    return self.a[len(self.layers)-2] &gt; threshold
</code></pre><h3 id="update">Update</h3><p>After computing the gradients of our weights ($dW$) and biases ($db$) during backpropagation, we might as well use them now to update said weights and biases. Since we stored the gradients in their own dictionaries (which is a class parameter), it is easy to call and update them. In contrast to our previous code, we introduced the learning rate. This is a mere factor that scales the strength of the applied update. Previously, we just set the learning rate to be a fixed 1 (and thus omitted it in the code).</p><pre><code class="language-python">def update(self, learning_rate: float):
    """
    Update the current weights and biases by multiplying the learning rate with the previously computed gradients.
    :param learning_rate: The step size of the gradient applied to update the weights and biases (e.g. to learn).
    """
    for idx in range(len(self.layers)-1):
        self.W[idx] -= learning_rate * self.dW[idx]
        self.b[idx] -= learning_rate * self.db[idx]  </code></pre><h3 id="training">Training</h3><p>Now that we have integrated the methods for working our way through the network (forth and back), computing the loss of each sample as well as updating the weights and biases, we can put everything together to implement the training procedure. Furthermore, we collect the loss of each epoch and return it as a list. This way, we can plot a nice learning curve in the end.</p><pre><code class="language-python">def fit(self, X: np.ndarray, y: np.ndarray, learning_rate: float = 1, epochs: int = 1000) -&gt; List:
    """
    Run the training procedure on the given data for the given epochs.
    This essentially fits the network to the given data.
    Print current loss value every epoch.
    :param X: Input data.
    :param y: True output data.
    :param learning_rate: The step size of the gradient applied to update the weights and biases (e.g. to learn).
    :param epochs: Number of training cycles to perform.
    :return: List of loss for each epoch.
    """
    loss_history = []
    
    for epoch in range(epochs):
        self.forward(X=X)
        loss = self.loss(y=y)
        self.backward(y=y)
        self.update(learning_rate)
        
        loss_history.append(loss.item())
        print(f"({epoch+1}/{epochs}): {loss.item()}")
        
    return loss_history
</code></pre><h3 id="accuracy">Accuracy</h3><p>Instead of <em>just</em> refactoring our previous code into a nice and handy class, we might as well add something new to it. Having a metric to know how accurately your (trained) model performs on a given dataset, is quite valuable. So this is what we are going to implement. Accuracy describes the ratio of correctly identified classes to all the classifications it predicted (correct and incorrect ones).</p><pre><code class="language-python">def accuracy(self, X: np.ndarray, y: np.ndarray) -&gt; float:
    """
    Perform predictions on all the given data (X) and compare these predictions to the ground truth values (y).
    Afterwards get the ratio of correctly to correctly+incorrectly predicted classes. This is the accuracy.
    :param X: Input data.
    :param y: True output data.
    :return: Accuracy as float value.
    """
    return np.sum(self.predict(X) == y) / y.size</code></pre><h3 id="testing">Testing</h3><p>Using the same XNOR data we had in the <a href="http://frank690.github.io/diy-neural-network-part-2/diy-neural-network-part-1/">previous post of this series</a>, we can confirm that we see near-identical results. Also, our accuracy on both, training and testing data confirms that we fitted our model (ANN) successfully to the generated data.</p><pre><code class="language-python">model = ANN([2,3,1])                # initialize our ANN model
loss = model.fit(X_train, y_train)  # fit it to our training data</code></pre><pre><code class="language-shell">(1/1000): 0.8624013698343836
(2/1000): 0.7502329385727288
(3/1000): 0.7085321817003911
...
(998/1000): 0.09573808006389115
(999/1000): 0.0956405468534334
(1000/1000): 0.0955433438225078</code></pre><pre><code class="language-python">model.accuracy(X_train, y_train)  # 0.975
model.accuracy(X_test, y_test)    # 0.955</code></pre><h3 id="training-loss-curve">(Training) Loss curve</h3><p>This is just the visualization of the list of loss values that we got from training the model. </p><figure class="kg-card kg-image-card"></figure><h3 id="summary">Summary</h3><p>And that's it! We successfully refactored our previous code into a single class that we can now use to easily create ANNs with arbitrary sizes (layers and number of neurons). Admittingly, there is still plenty of work to do from this point on. In the next posts of this series, we will add new capabilities to our ANN as well as continually improve its code structure, so that it always stays convenient for us to use. Click <a href="https://github.com/frank690/sffresch-code/blob/main/diy-neural-network-part-2/code.ipynb">here</a> to see the complete code of this post in a jupyter notebook.</p><p>Thank you for reading!</p>

            </section>

        </article>
    </main>
    <footer class="page-footer">
        <h3>sffresch</h3>
            <p>a blog about my projects</p>
        <p><a href="../../index.html">Read more posts â†’</a></p>
        <a class="powered" href="https://ghost.org" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 156 156"><g fill="none" fill-rule="evenodd"><rect fill="#15212B" width="156" height="156" rx="27"/><g transform="translate(36 36)" fill="#F6F8FA"><path d="M0 71.007A4.004 4.004 0 014 67h26a4 4 0 014 4.007v8.986A4.004 4.004 0 0130 84H4a4 4 0 01-4-4.007v-8.986zM50 71.007A4.004 4.004 0 0154 67h26a4 4 0 014 4.007v8.986A4.004 4.004 0 0180 84H54a4 4 0 01-4-4.007v-8.986z"/><rect y="34" width="84" height="17" rx="4"/><path d="M0 4.007A4.007 4.007 0 014.007 0h41.986A4.003 4.003 0 0150 4.007v8.986A4.007 4.007 0 0145.993 17H4.007A4.003 4.003 0 010 12.993V4.007z"/><rect x="67" width="17" height="17" rx="4"/></g></g></svg> Published with Ghost</a>
    </footer>
    
</body>
</html>
